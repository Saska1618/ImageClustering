{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2572d129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from art_clustering.data_loaders import WikiSubsetLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ba5c457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Feature Extraction\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, model_name='resnet18'):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        \n",
    "        # Use a pre-trained model like ResNet18\n",
    "        if model_name == 'resnet18':\n",
    "            self.model = models.resnet18(pretrained=True)\n",
    "            self.model = nn.Sequential(*list(self.model.children())[:-1])  # Remove the final classification layer\n",
    "        else:\n",
    "            raise ValueError(\"Currently only 'resnet18' is supported.\")\n",
    "        \n",
    "        # Put the model in evaluation mode (turn off dropout, batch norm)\n",
    "        self.model.eval()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            x = self.model(x)\n",
    "            x = torch.flatten(x, 1)  # Flatten to a 1D vector (batch_size, feature_dim)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "132c3b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Extracting features from the images using the FeatureExtractor model\n",
    "def extract_features(data_loader, model):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for images, labels in tqdm(data_loader, desc=\"Extracting features\"):\n",
    "        features = model(images)\n",
    "        all_features.append(features.cpu().numpy())\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    all_features = np.vstack(all_features)\n",
    "    all_labels = np.hstack(all_labels)\n",
    "    \n",
    "    return all_features, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3204c231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Dimensionality Reduction (Optional but Recommended)\n",
    "def reduce_dimensions(features, n_components=50):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    reduced_features = pca.fit_transform(features)\n",
    "    return reduced_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e51e8bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Clustering (KMeans in this case)\n",
    "def cluster_images(features, n_clusters=10):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    kmeans.fit(features)\n",
    "    return kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cee1f36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Putting it all together\n",
    "def process_and_cluster_images(data_loader, model_name='resnet18', n_clusters=10, n_components=50):\n",
    "    # Initialize feature extractor\n",
    "    model = FeatureExtractor(model_name=model_name)\n",
    "    model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Step 1: Extract features\n",
    "    features, labels = extract_features(data_loader, model)\n",
    "    \n",
    "    # Step 2: Reduce dimensionality\n",
    "    reduced_features = reduce_dimensions(features, n_components)\n",
    "    \n",
    "    # Step 3: Perform clustering\n",
    "    cluster_labels = cluster_images(reduced_features, n_clusters)\n",
    "    \n",
    "    return cluster_labels, labels, reduced_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a5867b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/algo_env/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/algo_env/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Extracting features: 100%|██████████| 431/431 [11:56<00:00,  1.66s/it]\n"
     ]
    }
   ],
   "source": [
    "# Now you can use your custom DataLoader to cluster the images\n",
    "\n",
    "data_loader = WikiSubsetLoader(root_dir='/Volumes/T7/university/sem2/wikiart/smol_data').get_loader()\n",
    "cluster_labels, true_labels, reduced_features = process_and_cluster_images(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f696cc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster labels: [5 8 5 3 3 7 9 4 2 4]\n",
      "True labels: [0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Display the clustering result\n",
    "print(f\"Cluster labels: {cluster_labels[:10]}\")  # Show the first 10 clusters\n",
    "print(f\"True labels: {true_labels[:10]}\")  # Show the first 10 true labels (optional, for comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b17509b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     38\u001b[39m     plt.show()\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Example usage after clustering:\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Assuming `all_features` is your extracted features and `cluster_labels` is the result of KMeans\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m features = \u001b[43mall_features\u001b[49m  \u001b[38;5;66;03m# These are your extracted feature vectors\u001b[39;00m\n\u001b[32m     43\u001b[39m cluster_labels = kmeans.labels_  \u001b[38;5;66;03m# Assuming you used KMeans and have the labels\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# Plot using PCA\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'all_features' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def plot_clusters(features, cluster_labels, method='PCA', n_components=2):\n",
    "    \"\"\"\n",
    "    Visualizes the clusters in 2D using PCA or t-SNE.\n",
    "\n",
    "    :param features: Feature vectors to be clustered\n",
    "    :param cluster_labels: The labels assigned by the clustering algorithm (e.g., KMeans)\n",
    "    :param method: Dimensionality reduction method ('PCA' or 't-SNE')\n",
    "    :param n_components: Number of components for reduction (2 for 2D plot)\n",
    "    \"\"\"\n",
    "    if method == 'PCA':\n",
    "        # Reduce the dimensions to 2D using PCA\n",
    "        pca = PCA(n_components=n_components)\n",
    "        reduced_features = pca.fit_transform(features)\n",
    "    elif method == 't-SNE':\n",
    "        # Reduce the dimensions to 2D using t-SNE\n",
    "        tsne = TSNE(n_components=n_components)\n",
    "        reduced_features = tsne.fit_transform(features)\n",
    "    else:\n",
    "        raise ValueError(\"Method must be 'PCA' or 't-SNE'\")\n",
    "\n",
    "    # Plot the clusters\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(reduced_features[:, 0], reduced_features[:, 1], c=cluster_labels, cmap='viridis', s=50, alpha=0.7)\n",
    "\n",
    "    # Add a color bar to indicate the cluster numbers\n",
    "    plt.colorbar(scatter)\n",
    "\n",
    "    # Set the title and labels\n",
    "    plt.title(f'Clusters Visualization using {method}', fontsize=16)\n",
    "    plt.xlabel('Component 1')\n",
    "    plt.ylabel('Component 2')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Example usage after clustering:\n",
    "# Assuming `all_features` is your extracted features and `cluster_labels` is the result of KMeans\n",
    "features = all_features  # These are your extracted feature vectors\n",
    "cluster_labels = kmeans.labels_  # Assuming you used KMeans and have the labels\n",
    "\n",
    "# Plot using PCA\n",
    "plot_clusters(features, cluster_labels, method='PCA')\n",
    "\n",
    "# Alternatively, you can plot using t-SNE\n",
    "plot_clusters(features, cluster_labels, method='t-SNE')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
